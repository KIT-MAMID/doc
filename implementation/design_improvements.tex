\section{Design Improvements}

In accordance with the project supervisor, a text-based delta between the original and implemented application design
is beyond the scope of this document.

However, to facilitate understanding and future maintenance of the code base, the design document has been updated to the state of
the implementation at the time of writing this document.

The purpose of this section is to provide an overview of the reasoning behind the design changes.

% one subsection per problem encountered during implementation

\subsection{Master: Database-Related Changes}

During the design phase of the project, it was decided to use the \refgo{gorm} ORM layer and a relational database as the backing store
for \mamid application data.

While never officially stated, the developers assumed SQlite 3 to be sufficient for the purposes of \mamid.

This assumption was proven wrong when enough of the master modules were implemented to reveal the limited capabilities of SQlite 3 regarding
concurrent access: updating a single row or column in the database effectively requires an exclusive lock on the entire database (see https://www.sqlite.org/lockingv3.html).
The various master components however udpate (disjoint!) rows or columns in parallel.

Given a substantial part of the master codebase had already been written expecting this behavior, the developers decided to switch to
PostgreSQL, a well-established open source relational database (see https://www.postgresql.org/).

PostgreSQL
\begin{itemize}
\item compiles in its most recent version 9.5.4 on the primary target operating system \textit{OpenIndiana 151a9} (also with TLS support)
\item allows for the degree of parallel database access required by the master
\item has features like foreign keys, data type checking and referential actions enabled by default %TODO ref
\item allows for redundant deployments \& zero downtime backups through the \codeinline{pg\_dump(1)} utility (optional criteria) %TODO ref
\item thus significantly reduces the risk of a corrupted database.
\end{itemize}

However, switching to PostgreSQL revealed flaws in the database schema auto-generated by the \refgo{gorm} ORM layer:

\begin{itemize}
\item Foreign keys and referential actions need to be defined as Go Field Tags in the model definition.
\item Schema migrations are only half-heartedly supported.
\end{itemize}

It was decided to define the database schema in plain SQL and to implement support for creating and migrating the schema in \mamid. %TODO this ok?

Effortless compatibility to \refgo{gorm} is maintained by following the documented conventions for naming columns (see http://jinzhu.me/gorm/models.html\#conventions) .

\subsection{Master: Cluster Allocator Prioritization Datastructures}

The \refgo{master.ClusterAllocator} is crucial for the stable operation of the \mamid-managed cluster.

The design document contains a pseudocode implementation of the \refgo{master.ClusterAllocator} algorithms managing Replica Set members.

However, pseudocode usually does not map directly to the concrete implementation.

For the implementation of MAMID, the priority queue datastructures used in the Cluster Allocator pseudocode proved impractical to implement:

\begin{itemize}
\item The master architecture follows the \textit{repository pattern}, meaning that decoupled components work together by sharing data
through the central database.
\item The Cluster Allocator algorithms need read access to a a substantial amount of the cluster model stored in the database
      in order to make allocation decisions.
\item The \refgo{gorm} ORM layer cannot record fine-grained changes to objects (missing dynamism in Go).
      Hence, saving updates to an object graph to database leads to an update of all attributes,
      inducing conflicting transactions with other components of MAMID.
\item Keeping the priority queue datastructures in sync with the database state during a \refgo{master.ClusterAllocator} run
      appears to be impossible with \refgo{gorm}.
\end{itemize}

Given these problems, the priority queues where replaced by SQL queries encoding the prioritization criteria.
Several SQL views were introduced to keep the prioritization queries concise and improve performance.
Testing did not reveal performance problems with the \refgo{master.ClusterAllocator} implementation.

\subsection{Replica Set Deployment with Keyfiles}\label{:di:keyfiles}

MongoDB supports several mechanisms for internal authentication between members of a Replica Set. The only mechanism available on the
the target operating system \textit{OpenIndiana 151a9} is authentication through a shared secret (\textit{keyfile}).

The supervisor's desire to have the deployed Mongods authenticate themselves to each other using this meachanism was not mentioned 
until 1.5 weeks before the implementation deadline. %TODO validate

Implementation of the feature proved problematic: Mongod instances started with the \textit{keyfile} parameter disable the \textit{localhost exception}
as soon as a Replica Set is configured and activate \textit{user access control}. %TODO review and ref
This was incompatible with the assumption made during the design phase that a Mongod would be always configurable by a its system user without authentication.

Hence, support for keyfiles required substantial changes to the deployment process late in the implementation phase:

\begin{itemize}
  \item Represent keyfile data in the Model \& MSP
  \item Represent user credential data in the Model \& MSP
  \item Support deployment of keyfiles in Master \& Slave
  \item Support authentication in the \refgo{slave.MongodConfigurator} by defining a \textit{management user}
  \item Deal with various edge-cases related to MongoDB \textit{write-concern} and the \textit{sharding role} of a Mongod
  \item Allow the user to retrieve keyfile and \textit{management user} credential through the GUI,
        e.g. to create additional users or configure sharding configuration servers.
\end{itemize}

Adapting the deployment process to work with the \textit{localhost exception} proved time-consuming.

In order to meet the implementation deadline, the \textit{keyfile} and \textit{management user} are currently

\begin{itemize}
  \item generated using a PRNG on first launch of the master
  \item global to all Mongods in the cluster
  \item unchangeable through the GUI / API.
\end{itemize}

The developers are aware of the security problems this situation implies and furthermore recommend using a target platform that supports
the MongoDB x509 authentication mechanism. %TODO ok?

\subsection{Slave: Mongod \& Replica Set Configuration}

The various edge-cases and subtleties of MongoDB were underestimated during the design phase of \mamid.

In particular, the following problems complicated and delayed the slave implementation:
\begin{description}
\item[Replica Set Initiation] Initiation must happen from a single Mongod in the soon-to-be Replica Set.
     This prohibits the original idea of simply broadcasting a state description to all Slaves hosting Mongods of the Replica Set,
        as is done once the ReplicaSet is initiated.
     A separate MSP protocol message \refgo{msp.RsInitiateMessage} was introduced and other sub-datastructures refactored, allowing
        a coordinated initiation of the Replica Set.
\item[User Access Control] The introduction of \textit{user access control} complicates the retrieval of Mongod state since most MongoDB
        commands relevant to the \refgo{master.Monitor} are only allowed when authenticated.
        The slave needs to cache the \textit{management user} credential received through the MSP.
\item[Situations without Primary] A Replica Set with a majority of Mongods unreachable cannot elect a new Primary.
        However, reconfiguring the Replica Set without overriding safety checks (\codeinline{force=true}) is not possible then.
        \mamid itself should not make the decision to override the safety checks because this behavior could lead to data loss.
\end{description}

Making the slave compatible with the the problems described above led significant bloat in the \refgo{slave.MongodConfigurator}.

To increase maintainability, the interaction with the MongoDB API was extracted into a private MongoDB API wrapper (\refgo{slave.mgoContext}).

\subsection{We realized: administrator needs more details on the deployment of the cluster in order to use it for applications}

=> GUI needs to display more information
    - Mongods of Replica Sets
    => requirement for Mongod API endpoint (expose what is already in the Master database)

=> Useful gimmics for the admin: ready to copy-to-clipboard 
    - command lines for starting a sharding config server
    - MongoDB URL useful for pasting into application configuration running on top of a Replica Set

\subsection{Original GUI draft does not scale well to 80-100 machines }

- use dense UI elements
- implement filtering functionality (cheap win using Angular!)

\subsection{Notifier config file}

A config file was added to the notifier to make the deployment easier for the administrator. The config file contains the SMTP relay host 
information, the master api endpoint and the path to the contacts file in a ini file. Also the api endpoint informtaion is used to generate 
links to affected Slaves \& Replica Sets in the notification e-mails.
